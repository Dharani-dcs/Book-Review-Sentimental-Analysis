{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import metrics \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import random\n",
    "from nltk.corpus import sentiwordnet as swn\n",
    "Adata_train=pd.read_csv(\"C:/Users/ADMIN/Documents/amazonTrainDataset.csv\",encoding=\"ISO-8859-1\")\n",
    "Adata_test=pd.read_csv(\"C:/Users/ADMIN/Documents/amazonTestDataset.csv\",encoding=\"ISO-8859-1\")\n",
    "training_data=[]\n",
    "test_data=[]\n",
    "\n",
    "l1=Adata_train['REVIEWS'].values\n",
    "l2=Adata_train['SENTIMENTS'].values\n",
    "\n",
    "for i in range(1,len(l1)):\n",
    "        l=[]\n",
    "        l.append(l1[i])\n",
    "        l.append(l2[i])\n",
    "        training_data.append(l)\n",
    "l3=Adata_test['REVIEWS'].values\n",
    "l4=Adata_test['SENTIMENTS'].values\n",
    "\n",
    "for i in range(1,len(l3)):\n",
    "        l=[]\n",
    "        l.append(l3[i])\n",
    "        l.append(l4[i])\n",
    "        test_data.append(l)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Best book for entrepreneurs. It gives great motivation and ideas', 'POSITIVE']\n",
      "97 48\n"
     ]
    }
   ],
   "source": [
    "# Examples from training data\n",
    "print(training_data[1])\n",
    "print(len(training_data), len(test_data))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "494\n",
      "265\n",
      "['150', 'a', 'achieve', 'affirmation', 'all', 'allow', 'alot', 'amazing', 'amazon', 'anable', 'and', 'another', 'area', 'arrived', 'atleast', 'author', 'available', 'average', 'awesome', 'bad', 'become', 'beginner', 'benjamin', 'best', 'bestseller', 'better', 'binding', 'bitter', 'boasting', 'book', 'booster', 'boring', 'but', 'buy', 'buying', 'can', 'case', 'change', 'changing', 'clear', 'completely', 'condition', 'confidence', 'content', 'cover', 'dad', 'damaged', 'decent', 'delivered', 'delivery', 'demographic', 'develop', 'different', 'disappointed', 'disappointing', 'download', 'easily', 'easy', 'edition', 'enough', 'entrepreneur', 'error', 'ever', 'everyone', 'exact', 'example', 'excellent', 'expectation', 'eye', 'finance', 'find', 'finished', 'first', 'fluff', 'for', 'formula', 'front', 'gentle', 'gift', 'give', 'given', 'giving', 'go', 'good', 'graham', 'great', 'guess', 'guy', 'gyan', 'habit', 'happen', 'hardcover', 'heard', 'help', 'honest', 'how', 'hyped', 'i', 'idea', 'impeccable', 'impression', 'improve', 'info', 'initially', 'instead', 'intelligence', 'interesting', 'issue', 'it', 'just', 'keep', 'kind', 'know', 'knowledge', 'language', 'lecture', 'lesson', 'lie', 'life', 'like', 'literature', 'little', 'long', 'look', 'looked', 'loos', 'lot', 'love', 'loved', 'make', 'management', 'many', 'met', 'mid', 'middle', 'missing', 'mistake', 'money', 'mostly', 'motivation', 'motivational', 'much', 'must', 'my', 'nd', 'never', 'new', 'nice', 'non', 'not', 'note', 'nothing', 'noticible', 'numbering', 'ok', 'okay', 'old', 'one', 'opener', 'ordered', 'otherwise', 'outdated', 'overall', 'packaging', 'page', 'paper', 'papper', 'people', 'person', 'please', 'poor', 'power', 'practical', 'printed', 'product', 'proper', 'providing', 'publication', 'quality', 'quite', 'r', 'read', 'reading', 'real', 'really', 'received', 'recommend', 'relate', 'replacement', 'requested', 'rich', 'richness', 'rule', 'same', 'say', 'search', 'secret', 'see', 'seek', 'seemed', 'self', 'sent', 'size', 'sleep', 'slightly', 'small', 'sorry', 'spelling', 'start', 'steam', 'story', 'stressed', 'study', 'stuff', 'success', 'successful', 'suck', 'superb', 'sweet', 'take', 'talk', 'term', 'the', 'there', 'thing', 'thinking', 'this', 'though', 'till', 'time', 'tip', 'to', 'too', 'topic', 'torn', 'truth', 'try', 'two', 'typing', 'u', 'uninteresting', 'unnecessarily', 'unnecessary', 'unrealistic', 'used', 'useful', 'usefull', 'useless', 'vague', 'very', 'visualization', 'want', 'wanted', 'waste', 'wasted', 'way', 'wealthy', 'when', 'whereas', 'wonderful', 'word', 'worst', 'would', 'yellow', 'yellowish']\n"
     ]
    }
   ],
   "source": [
    "#Required for Bag of words (unigram features) creation\n",
    "from nltk.corpus import stopwords \n",
    "from nltk.stem import WordNetLemmatizer\n",
    "#lemmatizer.lemmatize\n",
    "import re\n",
    "vocabulary = []\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "for tup in training_data:\n",
    "    words = re.sub(\"[^\\w]\",\" \",tup[0]).split() \n",
    "    cleaned_text = [lemmatizer.lemmatize(w.lower()) for w in words if w not in set(stopwords.words('english'))] #remove stop words  and stemming \n",
    "    vocabulary.extend(cleaned_text)\n",
    "    \n",
    "\n",
    "print(len(vocabulary))\n",
    "vocabulary = list(set(vocabulary))\n",
    "vocabulary.sort() #sorting the list\n",
    "\n",
    "print(len(vocabulary))\n",
    "print(vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_unigram_features(data,vocab):\n",
    "    fet_vec_all = []\n",
    "    for tup in data:\n",
    "        single_feat_vec = []\n",
    "        sent = tup[0].lower() #lowercasing the dataset\n",
    "        print(sent)\n",
    "        for v in vocab:\n",
    "            if sent.__contains__(v):\n",
    "                single_feat_vec.append(1)\n",
    "            else:\n",
    "                single_feat_vec.append(0)\n",
    "        fet_vec_all.append(single_feat_vec)       \n",
    "\n",
    "    return fet_vec_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_senti_wordnet_features(data):\n",
    "    fet_vec_all = []\n",
    "    for tup in data:\n",
    "        sent = tup[0].lower()\n",
    "        words = sent.split()\n",
    "        pos_score = 0\n",
    "        neg_score = 0\n",
    "        for w in words:\n",
    "           \n",
    "            senti_synsets = swn.senti_synsets(w.lower())\n",
    "            \n",
    "            for senti_synset in senti_synsets:\n",
    "                p = senti_synset.pos_score()\n",
    "                n = senti_synset.neg_score()\n",
    "                \n",
    "                pos_score+=p\n",
    "                neg_score+=n\n",
    "                break #take only the first synset (Most frequent sense)\n",
    "        fet_vec_all.append([float(pos_score),float(neg_score)])\n",
    "    return fet_vec_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_features(featureList1,featureList2):\n",
    "    # For merging two features\n",
    "    if featureList1==[]:\n",
    "        return featureList2\n",
    "    merged = []\n",
    "    for i in range(len(featureList1)):\n",
    "        m = featureList1[i]+featureList2[i]\n",
    "        merged.append(m)\n",
    "    return merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract the sentiment labels by making positive reviews as class 1 and negative reviews as class 2\n",
    "def get_lables(data):\n",
    "    labels = []\n",
    "    for tup in data:\n",
    "        if tup[1].lower()==\"negative\":\n",
    "            labels.append(-1)\n",
    "        else:\n",
    "            labels.append(1)\n",
    "        \n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_precision(prediction, actual):\n",
    "    prediction = list(prediction)\n",
    "    correct_labels = [predictions[i]  for i in range(len(predictions)) if actual[i] == predictions[i]]\n",
    "    precision = float(len(correct_labels))/float(len(prediction))\n",
    "    return precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def real_time_test(classifier,vocab):\n",
    "    print(\"Enter a sentence: \")\n",
    "    inp = input()\n",
    "    print(inp)\n",
    "    feat_vec_uni = get_unigram_features(inp,vocab)\n",
    "    feat_vec_swn =get_senti_wordnet_features(test_data)\n",
    "    feat_vec = merge_features(feat_vec_uni, feat_vec_swn)\n",
    "\n",
    "    predict = classifier.predict(feat_vec)\n",
    "    if predict[0]==1:\n",
    "        print(\"The sentiment expressed is: positive\")\n",
    "    else:\n",
    "        print(\"The sentiment expressed is: negative\")   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "awesome book\n",
      "best book for entrepreneurs. it gives great motivation and ideas\n",
      "good book just go for it.\n",
      "i was anable to download\n",
      "ok\n",
      "excellent book to read...papper quality is ok to read gentle.\n",
      "great product, no issues with paper quality, binding, or the condition it arrived in.\n",
      "there are better books available .\n",
      "a must read book gives a lot of life lessons\n",
      "one who seeks to improve his intelligence must read this book.\n",
      "for me it's a 'must read' if you want to develop all areas of your life.\n",
      "all secrets of how to achieve richness  be wealthy is printed in this book.\n",
      "good\n",
      "packaging was good, book met my all expectations.\n",
      " it takes example from many successful person  formula for success.\n",
      "superb book\n",
      "wanted to gift it to my dad.\n",
      "when i have start reading it and my life start changing.\n",
      "i don't know why this book is a bestseller.\n",
      "it's better to read management books atleast there are case studies.\n",
      "but i received two same books though i ordered only one\n",
      "ok\n",
      "pages are yellowish and looks old.\n",
      "initially this book was interesting to read.\n",
      "but overall decent read.\n",
      "the book starts off on a good note but looses its steams mid way..\n",
      "for beginners don't try its vague enough\n",
      "a nice read overall. but a little below expectations.\n",
      "small in size ,worst paper quality and some of the words are missing..\n",
      " many publications providing good or decent paper quality in rs.150/\n",
      "my guess is, this book is for a very different demographic that i can't relate to.\n",
      "bad cover page quality\n",
      "sent a old book .. completely disappointed \n",
      "the book quality is good...but the pages are not in proper numbering..\n",
      "it was a mistake buying this book. lots of fluff stuff. not useful\n",
      "damaged book is received requested for replacement will see\n",
      "very very poor quality.\n",
      "waste of money if you can really want \n",
      " how can amazon allow to happen such kind of things\n",
      "amazon keep it up\n",
      "superb \n",
      "a must read book gives alot of life lessons\n",
      "best best one of the best book....\n",
      "great book\n",
      "loved it\n",
      "must read this book\n",
      "best motivational literature\n",
      "wonderful book\n",
      "amazing\n",
      "eye opener and confidence booster \n",
      "nice  book\n",
      "best\n",
      "best book i would love to recommend everyone\n",
      "all the rules nd success tips are given in this\n",
      "quality of the book is good guys u all can buy\n",
      "just go buy another book\n",
      "average it's better to read management books atleast there are case studies.\n",
      "not much new info just talks a lot about the power of visualization. \n",
      "not good book very bad not usefull for us\n",
      "best book\n",
      "delivered on time but the front cover is in damaged condition. disappointed\n",
      "i did not like it .sorry\n",
      "this looked to me as one of the many self help books available.\n",
      "same motivational gyan whereas real life is too different!!!!!!!!!\n",
      "good\n",
      "all yellow and old pages\n",
      "not good \n",
      "very poor paper quality though it's a hardcover edition... very disappointing..\n",
      "to be honest, i never finished this book. it was vague and uninteresting.\n",
      " non practical people, better read books on finance from benjamin graham.\n",
      "much much hyped book\n",
      "this is the most useless book i have ever read\n",
      "the first impression goes for - product ordered at amazon.\n",
      "too long and topics are stressed unnecessarily.\n",
      "very interesting to read at the start till middle of the book\n",
      "outdated book\n",
      "too poor quality page\n",
      "it is all about your way of thinking and how to change it\n",
      "paper quality sucks\n",
      "okay\n",
      "boring lectures\n",
      "one of the pages were torn in between\n",
      "heard a lot about it but slightly seemed to me waste of time\n",
      "the book is impeccable in terms of knowledge but i received a used book.\n",
      "long long story u can sleep easily\n",
      "not clear and exact\n",
      "there are quite a few noticible typing mistakes and spelling errors\n",
      "delivery is good ...packaging is good .\n",
      "good book but it become boring to read it\n",
      "this book is more like affirmations to make you rich.\n",
      "easy language\n",
      "waste.wasted money\n",
      "average content\n",
      " book is very unrealistic!!author wants us to search for a secret in book ",
      "\n",
      " book that says otherwise just giving you sweet lies instead of the bitter truths. \n",
      "please don't go for this if you are new to the habit of reading books.\n",
      "i did not find as good as i heard\n",
      "nothing new and the author mostly talks and lot of unnecessary boasting .\n",
      "now i dont wish to analyse this further as for me its a great reason to welcome years to come.\n",
      "amezon keep it up\n",
      "a must read book gives alot of life lessons\n",
      "amazing book\n",
      "i am not saying that the book is bad but it is neither very good too.\n",
      "book....that everyone should read ..\n",
      "great book\n",
      "yes, this book will change your life forever. it definitely changed mine.\n",
      " 20 years ago i bought this book and it's ideas hook, line and sinker;\n",
      "i rarely give negative reviews on amazon but this book fully deserves it. go find something more current.\n",
      "book to empower your dreams\n",
      "might have been good at the time but there are much better books giving better detail and information these days\n",
      "a book for every mind and every dreamer\n",
      "in the case of think and grow rich, jaico beats everything.\n",
      "fabulous book and continuing to admire the work.\n",
      "practical otherwise it will be in your wish list and will never fulfill your desire.\n",
      "i do not see why anyone would not want to read this book.\n",
      "undoubtedly, 5 star with a big thumbs up for this masterpiece.\n",
      " in the end, this book will make you to grow rich.\n",
      "it's for you not for others!\n",
      "a worth reading book made unreadable because of poor quality pages\n",
      "so i decided to re-buy and read again, and it was now clear that amazing reads publishes stuff which is contaminated and reduced from the original content.\n",
      "it's a must read book.. totally worth reading.. it's a masterpiece... a formula for success! nailed it!\n",
      "go for it in your life once.\n",
      "anyways writing a book is not easy.kudos to the author to share his ideas.\n",
      "this is the most awesome and inspiring book i ever read in my whole life still today!\n",
      " thanks napoleon hill.\n",
      "it tells about all those above qualites and how to master them to be successful in life and to become more rich.\n",
      "their version of the book is complete, and untampered. i have checked. jaico is the best publisher for this book.\n",
      " i'm one of those who ordered by watching positive reviews.\n",
      " it teaches you the depth of thinking and changes the way of your normal approach to life.\n",
      "what you need to do is take action at the right time and the right time is now.\n",
      "anyone who wants to start reading, this is the perfect first step for you.\n",
      "i don't know how much of more valuable information i may lose(forced to skip) if i keep this book.\n",
      "thank you for your patience in reading my review\n",
      "so now for me the only way to grow rich is work hard and act smart\n",
      "when you really know what you want, set a plan to accomplish. let nothing stop you and you will be successful.\n",
      "success requires no explanations and failure permits no alibis.\"\n",
      "please don't go for this if you are new to the habit of reading books.. \n",
      "this book is only about its first chapter desire and in that too if you read onlg page no. 24 than its done. \n",
      "the insight you receive here will help you move from procrastination and fear to actualizing your goals.\n",
      "this is the best self help book any entrepreneur could ever read. perhaps the only one\n",
      "they need to. truly transformative.\n",
      "definitely a good read.\n",
      "think and grow rich' is not in reality a book at all, it is a way to change your life for the better. \n",
      "i think i am one of those that hill had described as \"ready for it\" ,i.e. the secret .\n",
      "definitely requires several reads\n",
      "all the secrets of how to achieve richness and be wealthy is printed in this book\n"
     ]
    }
   ],
   "source": [
    "\n",
    "training_unigram_features = get_unigram_features(training_data,vocabulary) # vocabulary extracted in the beginning\n",
    "training_swn_features = get_senti_wordnet_features(training_data)\n",
    "training_features = merge_features(training_unigram_features,training_swn_features)\n",
    "training_labels = get_lables(training_data)\n",
    "\n",
    "test_unigram_features = get_unigram_features(test_data,vocabulary)\n",
    "test_swn_features=get_senti_wordnet_features(test_data)\n",
    "test_features= merge_features(test_unigram_features,test_swn_features)\n",
    "\n",
    "test_gold_labels = get_lables(test_data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision of NB classifier is\n",
      "Training data\t0.9587628865979382\n",
      "Test data\t0.4583333333333333\n"
     ]
    }
   ],
   "source": [
    "# Naive Bayes Classifier \n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "nb_classifier = MultinomialNB().fit(training_features,training_labels) #training process\n",
    "predictions = nb_classifier.predict(test_features)\n",
    "\n",
    "print(\"Precision of NB classifier is\")\n",
    "predictions = nb_classifier.predict(training_features)\n",
    "precision = calculate_precision(predictions,training_labels)\n",
    "print(\"Training data\\t\" + str(precision))\n",
    "predictions = nb_classifier.predict(test_features)\n",
    "precision = calculate_precision(predictions,test_gold_labels)\n",
    "print(\"Test data\\t\" + str(precision))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision of linear SVM classifier is:\n",
      "Training data\t0.845360824742268\n",
      "Test data\t0.375\n"
     ]
    }
   ],
   "source": [
    "# SVM Classifier\n",
    "#Refer to : http://scikit-learn.org/stable/modules/svm.html\n",
    "from sklearn.svm import LinearSVC\n",
    "svm_classifier = LinearSVC(penalty='l2', C=0.01).fit(training_features,training_labels)\n",
    "predictions = svm_classifier.predict(training_features)\n",
    "\n",
    "print(\"Precision of linear SVM classifier is:\")\n",
    "precision = calculate_precision(predictions,training_labels)\n",
    "print(\"Training data\\t\" + str(precision))\n",
    "predictions = svm_classifier.predict(test_features)\n",
    "precision = calculate_precision(predictions,test_gold_labels)\n",
    "print(\"Test data\\t\" + str(precision))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
